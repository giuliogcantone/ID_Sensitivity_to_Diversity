---
title: "Sampling from OA"
author: "GG Cantone"
date: "2023-06-02"
output:
---

In case you have not the package manager `pacman`, install it.

```{r}
install.packages(pacman)
```

Setup

```{r setup, include=FALSE}
pacman::p_load(
  tidyverse,
  openalexR,
  readr,
  janitor,
  ggExtra
)
```

---

Sampling all concepts

```{r}
oa_fetch(
  entity = "concepts",
  level = c(0:1)
) -> OA_concepts

OA_concepts %>%
  rename(concept = display_name,
         rel=related_concepts) %>%
  select(concept,
         level,
         rel) %>%
  unnest(rel,
         names_sep = "_") %>%
  rename(rel_concept = rel_display_name) %>%
  select(concept,
         level,
         rel_id,
         rel_concept,
         rel_level,
         rel_score,
         ) %>%
  filter(rel_level <2)  -> OAc_proximity
```

---

Importing WOS

```{r}
read_csv("Scientific.csv") %>%
  add_row(read_csv("Social_Sciences.csv")) %>%
  select(-`Publisher address`) %>%
  distinct(`Journal title`,
           .keep_all = T) %>%
  pivot_longer(cols = c("ISSN","eISSN"),
               names_to = "Type",
               values_to = "ISSN"
  ) %>%
  select(-Type) %>%
  distinct(`Journal title`,
           .keep_all = T) -> WoS_j
```

Importing WoS Fields

```{r}
read_csv("WoS_categories.csv") %>%
  filter(Edition == "ESCI") %>%
  select(Category,Group) -> Wos_SC
```


Download OpenAlex data on journals

```{r}
oa_fetch(
  entity = "venues",
  issn = WoS_j$ISSN
) -> journals
```

Joins of categories

```{r}
journals %>%
  transmute(id_j = id,
         journal = display_name,
         main_issn = issn_l %>% as.character(),
         n_papers = works_count,
         x_concepts) %>%
  left_join(WoS_j %>%
              rename(WoS_JSC = `Web of Science Categories`,
                     main_issn = ISSN
                     ) %>%
              select(main_issn,WoS_JSC,
                     Languages)) %>%
  filter(!WoS_JSC %>% is.na(),
         !x_concepts %>% is.na()) -> db_j
```

Data cleaning

```{r}
db_j %>%
  mutate(stnd_WoS_JSC = WoS_JSC %>%
           str_replace("Public, Environmental & Occupational Health",
                       "Public Health") %>%
           str_replace_all(",",":") %>%
           str_replace_all(" \\| ",", "),
         coarse_WoS_JSC = stnd_WoS_JSC %>%
           str_remove_all("\\:.*?(?=,|$)"),
         coarse_WoS_JSC =
           map_chr(str_split(coarse_WoS_JSC,", "),
                   ~ str_c(unique(.x), collapse = ", ")),
         mention_multidis = str_detect(tolower(WoS_JSC),"multidis|interdis"),
         n_stnd = str_count(stnd_WoS_JSC,","),
         multidis = if_else((n_stnd == 0) &
                              (mention_multidis == 0),
                            0,1)
         ) %>%
  mutate(x_concepts = map(x_concepts, ~ filter(.x,level < 2))
         ) -> db_j

```

How many combinations of WOS categories?

```{r}

db_j %>%
  count(coarse_WoS_JSC) %>% View()

db_j %>%
  count(stnd_WoS_JSC) %>% View()

db_j %>%
  filter(multidis == F) %>%
  count(stnd_WoS_JSC) %>% View()

```


Map mono-disciplinary association
with Berger correlation

```{r}

db_j %>%
  filter(multidis == 0) %>%
  unnest(x_concepts) %>%
  summarise(score = sum(score*n_papers),
            .by = c(stnd_WoS_JSC,display_name)
            ) %>%
  rename(max_OpAl_JSC = display_name) %>%
  arrange(stnd_WoS_JSC,-score) %>%
  mutate(max_score = score/sum(score),
         .by = stnd_WoS_JSC) %>%
  adorn_rounding(4) %>%
  filter(score == max(score),
         .by = stnd_WoS_JSC) %>%
  mutate(name_lgt = str_length(stnd_WoS_JSC)) -> berger_map

berger_map %>%
  count(max_OpAl_JSC) %>%
  arrange(-n)

```


Marginal Scatterplot

```{r}
ggMarginal(berger_map %>%
  ggplot(aes(x = score,
             y = name_lgt)
         )+
  geom_point())
```



## 

Sample papers

```{r}
oa_fetch(
  entity = "works",
  abstract = F,
  publication_year = c(2011:2015),
  type = "journal-article",
  options = list(sample = 10)
) -> sample
```
